{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penggabungan Series/Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append\n",
    "import pandas as pd\n",
    "# Buat series of int (s1) dan series of string (s2)\n",
    "s1 = pd.Series([1,2,3,4,5,6])\n",
    "s2 = pd.Series([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"])\n",
    "# Terapkan method append\n",
    "s2_append_s1 = s2.append(s1)\n",
    "print(\"Series - append:\\n\", s2_append_s1)\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({'a':[1,2],\n",
    "\t\t   'b':[3,4]})\n",
    "df2 = pd.DataFrame({'b':[1,2],\n",
    "\t\t   'a':[3,4]})\n",
    "# Terapkan method append\n",
    "df2_append_df1 = df2.append(df1)\n",
    "print(\"Dataframe - append:\\n\", df2_append_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({'a':[1,2],\n",
    "\t\t\t\t\t'b':[3,4]})\n",
    "df2 = pd.DataFrame({'b':[1,2],\n",
    "\t\t\t\t\t'a':[3,4]})\n",
    "# Terapkan method concat row-wise\n",
    "row_wise_concat = pd.concat([df2, df1])\n",
    "print(\"Row-wise - concat:\\n\", row_wise_concat)\n",
    "# Terapkan method concat column-wise\n",
    "col_wise_concat = pd.concat([df2, df1],axis=1)\n",
    "print(\"Column-wise - concat:\\n\", col_wise_concat)\n",
    "# Penambahan identifier --> membentuk hasil penggabungan multiindex\n",
    "multiindex_concat = pd.concat([df2, df1], axis=0, keys=['df1','df2'])\n",
    "print(\"Multiindex - concat:\\n\", multiindex_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge - Part 1\n",
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "})\n",
    "# Merge yang ekivalen dengan SQL left join\n",
    "merge_df_left = pd.merge(left=df2, right=df1, how='left', left_on='key', right_on='key')\n",
    "print('Merge - Left:\\n', merge_df_left)\n",
    "# Merge yang ekivalen dengan SQL right join\n",
    "merge_df_right = pd.merge(left=df2, right=df1, how='right', left_on='key', right_on='key')\n",
    "print('Merge - Right:\\n', merge_df_right)\n",
    "# Merge yang ekivalen dengan SQL inner join\n",
    "merge_df_inner = pd.merge(left=df2, right=df1, how='inner', left_on='key', right_on='key')\n",
    "print('Merge - Inner:\\n', merge_df_inner)\n",
    "# Merge yang ekivalen dengan SQL outer join\n",
    "merge_df_outer = pd.merge(left=df2, right=df1, how='outer', left_on='key', right_on='key')\n",
    "print('Merge - Outer:\\n', merge_df_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge - Part 2\n",
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "}).set_index(['key','val2'])\n",
    "print('Dataframe 1:\\n', df1)\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "}).set_index(['key','val3'])\n",
    "print('Dataframe 2:\\n', df2)\n",
    "# Merge dataframe yang memiliki multi index\n",
    "df_merge = pd.merge(df1.reset_index(),df2.reset_index())\n",
    "print('Merging dataframe:\\n', df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join\n",
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "})\n",
    "# Penerapan join dengan menggunakan set_index dan keyword how\n",
    "join_df = df1.set_index('key').join(df2.set_index('key'), how='outer')\n",
    "print(join_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot, Melt, Stack & Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns= ['kelas','murid','pelajaran','nilai'])\n",
    "# Unique value pada setiap kolom data\n",
    "for column in data.columns:\n",
    "    print('Unique value %s: %s' % (column, data[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting with single column measurement\n",
    "pivot1 = data.pivot(index='murid', columns='pelajaran', values='nilai')\n",
    "print('Pivoting with single column measurement:\\n', pivot1)\n",
    "# Pivoting with multiple column measurement\n",
    "pivot2 = data.pivot(index='murid', columns='pelajaran')\n",
    "print('Pivoting with multiple column measurement:\\n', pivot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot_Table\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='mean'\n",
    "pivot_tab_mean = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean')\n",
    "print('Creating pivot table -- aggfunc mean:\\n', pivot_tab_mean)\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='median'\n",
    "pivot_tab_median = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='median')\n",
    "print('Creating pivot table -- aggfunc median:\\n', pivot_tab_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt - Part 1\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting dataframe\n",
    "data_pivot = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean').reset_index()\n",
    "print('Pivoting dataframe:\\n', data_pivot)\n",
    "# [1] Melting dataframe data_pivot\n",
    "data_melt_1 = pd.melt(data_pivot)\n",
    "print('Melting dataframe:\\n', data_melt_1)\n",
    "# [2] Melting dataframe data_pivot dengan id_vars\n",
    "data_melt_2 = pd.melt(data_pivot, id_vars='kelas')\n",
    "print('Melting dataframe dengan idvars:\\n', data_melt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt - Part 2\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting dataframe\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai', aggfunc='mean').reset_index()\n",
    "print('Pivoting dataframe:\\n', data_pivot)\n",
    "# [3.a] Melting dataframe data_pivot dengan value_vars\n",
    "data_melt_3a = pd.melt(data_pivot, value_vars=['math'])\n",
    "print('Melting dataframe dengan value_vars:\\n', data_melt_3a)\n",
    "# [3.b] Melting dataframe data_pivot dengan id_vars dan value_vars\n",
    "data_melt_3b = pd.melt(data_pivot, id_vars='kelas', value_vars=['math'])\n",
    "print('Melting dataframe dengan id_vars dan value_vars:\\n', data_melt_3b)\n",
    "# [4] Melting dataframe data_pivot dengan id_vars, value_vars, var_name. dan value_name\n",
    "data_melt_4 = pd.melt(data_pivot, id_vars='kelas', value_vars=['english','math'], var_name='pelajaran', value_name='nilai')\n",
    "print('Melting dataframe dengan id_vars, value_vars, var_name. dan value_name:\\n', data_melt_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack & Unstack - Part 1\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "print('Dataframe:\\n', data)\n",
    "# Set index data untuk kolom kelas, murid, dan pelajaran\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\n",
    "print('Dataframe multi index:\\n', data)\n",
    "# [1] Unstacking dataframe\n",
    "data_unstack_1 = data.unstack()\n",
    "print('Unstacking dataframe:\\n', data_unstack_1)\n",
    "# [2] Unstacking dengan specify level name\n",
    "data_unstack_2 = data.unstack(level='murid')\n",
    "print('Unstacking dataframe dengan level name:\\n', data_unstack_2)\n",
    "# [3] Unstacking dengan specify level position\n",
    "data_unstack_3 = data.unstack(level=1)\n",
    "print('Unstacking dataframe dengan level position:\\n', data_unstack_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack & Unstack - Part 2\n",
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\n",
    "data_unstack = data.unstack(level=1)\n",
    "print('Dataframe:\\n', data_unstack)\n",
    "# [1] Stacking dataframe\n",
    "data_stack = data_unstack.stack()\n",
    "print('Stacked dataframe:\\n', data_stack)\n",
    "# [2] Tukar posisi index setelah stacking dataframe\n",
    "data_swap = data_stack.swaplevel(1,2)\n",
    "print('Swapped data:\\n', data_swap)\n",
    "# [3] Melakukan sort_index pada stacking dataframe\n",
    "data_sort = data_swap.sort_index()\n",
    "print('Sorted data:\\n', data_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation & GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Inspeksi Data\n",
    "import pandas as pd\n",
    "# Load data global_air_quality.csv\n",
    "global_air_quality = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "print('Lima data teratas:\\n', global_air_quality.head())\n",
    "# Melakukan pengecekan terhadap data\n",
    "print('Info global_air_quality:\\n', global_air_quality.info())\n",
    "# Melakukan count tanpa groupby\n",
    "print('Count tanpa groupby:\\n', global_air_quality.count())\n",
    "# Melakukan count dengan groupby \n",
    "gaq_groupby_count = global_air_quality.groupby('source_name').count()\n",
    "print('Count dengan groupby (5 data teratas):\\n', gaq_groupby_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby dan Aggregasi dengan Fungsi Statistik Dasar\n",
    "import pandas as pd\n",
    "# Load data global_air_quality.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "# Create variabel pollutant \n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\n",
    "# [1] Group berdasarkan country dan terapkan aggregasi mean\n",
    "pollutant_mean = pollutant.groupby('country').mean()\n",
    "print('Rata-rata pollutant (5 teratas):\\n', pollutant_mean.head())\n",
    "# [2] Group berdasarkan country dan terapkan aggregasi std\n",
    "pollutant_std = pollutant.groupby('country').std().fillna(0)\n",
    "print('Standar deviasi pollutant (5 teratas):\\n', pollutant_std.head())\n",
    "# [3] Group berdasarkan country dan terapkan aggregasi sum\n",
    "pollutant_sum = pollutant.groupby('country').sum()\n",
    "print('Total pollutant (5 teratas):\\n', pollutant_sum.head())\n",
    "# [4] Group berdasarkan country dan terapkan aggregasi nunique\n",
    "pollutant_nunique = pollutant.groupby('country').nunique()\n",
    "print('Jumlah unique value pollutant (5 teratas):\\n', pollutant_nunique.head())\n",
    "# [5] Group berdasarkan country dan terapkan aggregasi first\n",
    "pollutant_first = pollutant.groupby('country').first()\n",
    "print('Item pertama pollutant (5 teratas):\\n', pollutant_first.head())\n",
    "# [6] Group berdasarkan country dan terapkan aggregasi last\n",
    "pollutant_last = pollutant.groupby('country').last()\n",
    "print('Item terakhir pollutant (5 teratas):\\n', pollutant_last.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby dengan Custom Aggregations\n",
    "import pandas as pd\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "# Create variabel pollutant \n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\n",
    "# Create sebuah function: iqr\n",
    "def iqr(series):\n",
    "\tQ1 = series.quantile(0.25)\n",
    "\tQ3 = series.quantile(0.75)\n",
    "\treturn Q3 - Q1\n",
    "# Group berdasarkan country dan terapkan aggregasi dari function: iqr\n",
    "custom_agg = pollutant.groupby('country').agg(iqr)\n",
    "print('Custom aggregation (5 teratas):\\n', custom_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby dengan Custom Aggregations by dict\n",
    "import pandas as pd\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "# Create variabel pollutant \n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\n",
    "# Function IQR\n",
    "def iqr(series):\n",
    "\treturn series.quantile(0.75) - series.quantile(0.25)\n",
    "# Create custom aggregation using dict\n",
    "custom_agg_dict = pollutant['value'][['pm10','pm25','so2']].groupby('country').agg({\n",
    "   'pm10':'median',\n",
    "   'pm25':iqr,\n",
    "   'so2':iqr\n",
    "})\n",
    "print('\\nCetak 5 data teratas custom_agg_dict:\\n', custom_agg_dict.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset as TimeSeries\n",
    "import pandas as pd\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv', parse_dates=True, index_col='timestamp')\n",
    "# Cetak 5 data teratas\n",
    "print(gaq.head())\n",
    "# Cetak info dari dataframe gaq\n",
    "print('info')\n",
    "print(gaq.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Datetime\n",
    "import pandas as pd\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "# Cetak 5 data teratas\n",
    "print('Sebelum diubah dalam format datetime:\\n', gaq.head())\n",
    "# Ubah menjadi datetime\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\n",
    "gaq = gaq.set_index('timestamp')\n",
    "# Cetak 5 data teratas\n",
    "print('Sesudah diubah dalam format datetime:\\n', gaq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling Data\n",
    "import pandas as pd\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\n",
    "gaq = gaq.set_index('timestamp')\n",
    "print('Dataset sebelum di-downsampling (5 teratas):\\n', gaq.head())\n",
    "# [1] Downsampling dari daily to weekly dan kita hitung maksimum untuk seminggu\n",
    "gaq_weekly = gaq.resample('W').max()\n",
    "print('Downsampling daily to weekly - max (5 teratas):\\n', gaq_weekly.head())\n",
    "# [2] Downsampling dari daily to quaterly dan kita hitung minimumnya untuk tiap quarter\n",
    "gaq_quaterly = gaq.resample('Q').min()\n",
    "print('Downsampling daily to quaterly - min (5 teratas):\\n', gaq_quaterly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling Data\n",
    "import pandas as pd\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\n",
    "gaq = gaq.set_index('timestamp')\n",
    "print('Dataset sebelum di-upsampling (5 teratas):\\n', gaq.head())\n",
    "# Upsampling dari daily to hourly dan kita hitung reratanya\n",
    "gaq_hourly = gaq.resample('H').mean()\n",
    "print('Upsampling daily to hourly - mean (5 teratas):\\n', gaq_hourly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling by Frequency\n",
    "import pandas as pd\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\n",
    "gaq = gaq.set_index('timestamp')\n",
    "print('Dataset sebelum di-resampling (5 teratas):\\n', gaq.head())\n",
    "# Resample dari daily to 2 monthly, hitung reratanya, dan fillna = 'bfill'\n",
    "gaq_2monthly = gaq.resample('2M').mean().fillna(method='bfill')\n",
    "print('Resampling daily to 2 monthly - mean - ffill (5 teratas):\\n', gaq_2monthly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\n",
    "gaq = gaq.set_index('timestamp')\n",
    "# [1] Membuat pivot table yang menunjukkan waktu di baris nya dan masing-masing value dari pollutant nya dalam kolom\n",
    "gaq_viz = gaq[['pollutant','value']].reset_index().set_index(['timestamp','pollutant'])\n",
    "gaq_viz = gaq_viz.pivot_table(index='timestamp', columns='pollutant', aggfunc='mean').fillna(0)\n",
    "gaq_viz.columns = gaq_viz.columns.droplevel(0)\n",
    "print('Data (5 teratas):\\n', gaq_viz.head())\n",
    "# [2] Membuat fungsi yang memberikan default value 0 ketika value nya di bawah 0 dan apply ke setiap elemen dari dataset tersebut, kemudian menampilkannya sebagai chart\n",
    "def default_val(val):\n",
    " if val < 0:\n",
    "   return 0\n",
    " else:\n",
    "   return val\n",
    "line1 = gaq_viz.resample('M').mean().ffill().applymap(lambda x: default_val(x)).apply(lambda x: x/x.max()) # default value if value < 0 then 0, kemudian menghasilkan % value = value/max(value)\n",
    "line1.plot(\n",
    "   title = 'average value of each pollutant over months',\n",
    "   figsize = (10,10), #ukuran canvas 10px x 10px\n",
    "   ylim = (0,1.25), #memberikan batas tampilan y-axis hanya 0 sampai 125%\n",
    "   subplots = True #memecah plot menjadi beberapa bagian sesuai dengan jumlah kolom\n",
    ")\n",
    "plt.ylabel('avg pollutant (%)')\n",
    "plt.xlabel('month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performa Penjualan di setiap Cabang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# [1]. Load masing-masing data dengan pandas\n",
    "retail_data1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_1_until_3.csv')\n",
    "retail_data2 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_4_until_6.csv')\n",
    "retail_data3 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_7_until_9.csv')\n",
    "retail_data4 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/retail_data_from_10_until_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]. Pengecekan Data\n",
    "print('PENGECEKAN DATA\\n\\n')\n",
    "#      Cek data sekilas (tampilkan 5 baris teratas)\n",
    "print(retail_data1.head())\n",
    "#      Cek list kolom untuk semua dataframe\n",
    "print('Kolom retail_data1: %s' %retail_data1.columns)\n",
    "print('Kolom retail_data2: %s' %retail_data2.columns)\n",
    "print('Kolom retail_data3: %s' %retail_data3.columns)\n",
    "print('Kolom retail_data4: %s' %retail_data4.columns)\n",
    "#      Concat multiple dataframe menjadi 1 dataframe\n",
    "retail_table = pd.concat([retail_data1,retail_data2,retail_data3,retail_data4])\n",
    "print('\\nJumlah baris:', retail_table.shape[0])\n",
    "#      Pengecekan dataframe info\n",
    "print('\\nInfo:')\n",
    "print(retail_table.info())\n",
    "#      Pengecekan statistik deskriptif\n",
    "print('\\nStatistik deskriptif:\\n', retail_table.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3]. Transformasi Data\n",
    "print('TRANSFORMASI DATA\\n\\n')\n",
    "#      Memastikan data yang memiliki item_price < 0 atau total_price < 0\n",
    "cek = retail_table.loc[(retail_table['item_price'] < 0) | (retail_table['total_price'] < 0)]\n",
    "print('\\nitem_price < 0 atau total_price < 0:\\n', cek)\n",
    "#      Jika tidak masuk akal datanya dapat dibuang\n",
    "if cek.shape[0] != 0:\n",
    "\tretail_table = retail_table.loc[(retail_table['item_price'] > 0) & (retail_table['total_price'] > 0)]\n",
    "#      Cek apakah masih ada order_id yang bernilai undefined dan delete row tersebut\n",
    "cek = retail_table.loc[retail_table['order_id'] == 'undefined']\n",
    "print('\\norder_id yang bernilai undefined:\\n', cek)\n",
    "#      Jika ada maka buang baris tersebut\n",
    "if cek.shape[0] != 0:\n",
    "\tretail_table = retail_table.loc[retail_table['order_id'] != 'undefined']\n",
    "\n",
    "#      Transform order_id menjadi int64\n",
    "retail_table['order_id'] = retail_table['order_id'].astype('int64')\n",
    "#      Transform order_date menjadi datetime Pandas\n",
    "retail_table['order_date'] = pd.to_datetime(retail_table['order_date'])\n",
    "#      Cek dataframe info kembali untuk memastikan\n",
    "print('\\nInfo:')\n",
    "print(retail_table.info())\n",
    "#      Cek statistik deskriptif kembali, untuk memastikan\n",
    "print('\\nStatistik deskriptif:\\n', retail_table.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4]. Filter hanya 5 province terbesar di pulau Jawa\n",
    "print('\\nFILTER 5 PROVINCE TERBESAR DI PULAU JAWA\\n')\n",
    "java = ['DKI Jakarta','Jawa Barat','Jawa Tengah','Jawa Timur','Yogyakarta']\n",
    "retail_table = retail_table.loc[retail_table['province'].isin(java)]\n",
    "#      Untuk memastikan kolom provinsi isinya sudah sama dengan java\n",
    "print(retail_table['province'].unique())\n",
    "\n",
    "# [5]. Kelompokkan sesuai dengan order_date dan province kemudian aggregasikan\n",
    "groupby_city_province = retail_table.groupby(['order_date', 'province']).agg({\n",
    "   'order_id': 'nunique',\n",
    "   'customer_id': 'nunique',\n",
    "   'product_id': 'nunique',\n",
    "   'brand': 'nunique',\n",
    "   'total_price': sum\n",
    "})\n",
    "#      Ubah nama kolomnya menjadi 'order','customer','product','brand','GMV'\n",
    "groupby_city_province.columns = ['order', 'customer', 'product', 'brand', 'GMV']\n",
    "print('\\ngroupby_city_province (10 data teratas):\\n', groupby_city_province.head(10))\n",
    "\n",
    "# [6]. Unstack untuk mendapatkan order_date di bagian baris dan province di bagian column\n",
    "unstack_city_province = groupby_city_province.unstack('province').fillna(0)\n",
    "print('\\nunstack_city_province (5 data teratas):\\n', unstack_city_province.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7]. Slicing data untuk masing-masing measurement, misal: order\n",
    "idx = pd.IndexSlice\n",
    "by_order = unstack_city_province.loc[:,idx['order']]\n",
    "print('\\nby order (5 data teratas):\\n', by_order.head())\n",
    "\n",
    "# [8]. Lakukan resampling pada data tersebut untuk dilakukan perhitungan rata-rata bulanan \n",
    "by_order_monthly_mean = by_order.resample('M').mean()\n",
    "print('\\nby_order_monthly_mean (5 data teratas):\\n', by_order_monthly_mean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# [9]. Plot untuk hasil pada langkah #[8]\n",
    "by_order_monthly_mean.plot(\n",
    "   figsize = (8,5),\n",
    "   title = 'Average Daily order Size in Month View for all Province'\n",
    ")\n",
    "plt.ylabel('avg order size')\n",
    "plt.xlabel('month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure canvas dan axes for 5 line plots\n",
    "fig, axes = plt.subplots(5, 1, figsize=(8, 25))\n",
    "\n",
    "# Slicing index\n",
    "idx = pd.IndexSlice\n",
    "for i, measurement in enumerate(groupby_city_province.columns):\n",
    "    # Slicing data untuk masing-masing measurement\n",
    "    by_measurement = unstack_city_province.loc[:,idx[measurement]]\n",
    "    # Lakukan resampling pada data tersebut untuk dilakukan perhitungan rata-rata bulanan \n",
    "    by_measurement_monthly_mean = by_measurement.resample('M').mean()\n",
    "    # Plot by_measurement_monthly_mean\n",
    "    by_measurement_monthly_mean.plot(\n",
    "        title = 'Average Daily ' + measurement + ' Size in Month View for all Province',\n",
    "        ax = axes[i]\n",
    "    )\n",
    "    axes[i].set_ylabel('avg ' + measurement + ' size')\n",
    "    axes[i].set_xlabel('month')\n",
    "\n",
    "# Adjust the layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
